{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3Q/b8mra+eVNa3hs4qrsZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abxda/Aurora_s1_estdesc/blob/main/Semana_1_Aurora_EstDesc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#https://abxda.github.io/Aurora_s1_estdesc/"
      ],
      "metadata": {
        "id": "3SnvtD80G7ZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "¡Estimados futuros Científicos de Datos! Abordemos una de las preguntas más fundamentales y a la vez fascinantes de la estadística inferencial: **¿Por qué funciona el muestreo aleatorio?** Y, más importante aún, ¿cómo nos ayuda el majestuoso Teorema Central del Límite (TCL) a entenderlo?\n",
        "\n",
        "Prepárense para un viaje intuitivo, lleno de simulaciones en Python, que nos llevará desde lo más básico del muestreo hasta las puertas de la inferencia estadística. ¡Vamos a desentrañar este misterio juntos!"
      ],
      "metadata": {
        "id": "XzBfm4zi6MmD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### **1. La Necesidad del Muestreo: ¿Por qué no estudiamos a toda la población?**\n",
        "\n",
        "Imaginemos que ustedes son Científicos de Datos trabajando para una gran empresa de telecomunicaciones y quieren saber el ingreso promedio de *todos* sus clientes en México. ¿Sería posible preguntarles a los 120 millones de mexicanos si son clientes y, de serlo, cuánto ganan? ¡Absolutamente no! Sería una tarea gigantesca, costosísima y que consumiría muchísimo tiempo, casi imposible de realizar.\n",
        "\n",
        "Aquí es donde entra en juego la magia del **muestreo**. En lugar de estudiar a toda la **población** (el conjunto total de individuos o elementos de interés), tomamos una **muestra** (un subconjunto representativo de esa población). Nuestro objetivo es obtener conclusiones válidas y significativas sobre la población basándonos únicamente en la información de esa muestra.\n",
        "\n",
        "*   **Parámetro Poblacional:** Es una característica numérica que describe a la *población completa* (ej. el ingreso promedio real de *todos* los clientes). Es un valor fijo, pero usualmente desconocido.\n",
        "*   **Estadístico Muestral:** Es una característica numérica que describe a la *muestra* (ej. el ingreso promedio de los clientes en nuestra muestra). Este valor *puede variar* de una muestra a otra.\n",
        "\n",
        "La gran pregunta es: ¿cómo aseguramos que lo que observamos en nuestra pequeña muestra realmente nos dice algo confiable sobre la enorme población? Si elegimos mal nuestra muestra, podemos llegar a conclusiones muy erróneas, ¡lo que en Ciencia de Datos puede tener consecuencias catastróficas!.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### **2. La Ley de los Grandes Números: Cuando el tamaño importa**\n",
        "\n",
        "La primera pieza de nuestro rompecabezas es la **Ley de los Grandes Números (LGN)**. Este teorema, aunque más sencillo que el Teorema Central del Límite, nos da una intuición poderosa sobre por qué el muestreo funciona.\n",
        "\n",
        "En pocas palabras, la LGN nos dice que **cuanto mayor sea el tamaño de nuestra muestra, más se acercará el valor del estadístico muestral (por ejemplo, la media de la muestra) al verdadero parámetro poblacional**. Piensen en esto: si ustedes empiezan a preguntar a más y más personas, eventualmente habrán preguntado a casi toda la población, y en ese punto, el promedio de su muestra será prácticamente el mismo que el promedio de la población. ¡Tiene mucho sentido, verdad!\n",
        "\n",
        "Vamos a visualizar esto con una simulación.\n",
        "\n",
        "#### **Simulación 1: La Media Muestral se Acerca a la Media Poblacional**\n",
        "\n",
        "Imaginemos una población con una distribución de ingresos no muy común, quizás sesgada. Digamos que la media de ingreso de esta población es $\\mu = 50,000$."
      ],
      "metadata": {
        "id": "AUQAlzNo6ghs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-TUM6vZ5rM8"
      },
      "outputs": [],
      "source": [
        "# Importamos las librerías que vamos a necesitar\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import norm, expon, uniform\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Configuramos el estilo de las gráficas para que se vean bonitas\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "plt.rcParams['axes.titlesize'] = 12\n",
        "plt.rcParams['axes.labelsize'] = 10\n",
        "plt.rcParams['xtick.labelsize'] = 8\n",
        "plt.rcParams['ytick.labelsize'] = 8\n",
        "plt.rcParams['legend.fontsize'] = 8"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Definimos una población hipotética (ej. ingresos de clientes)\n",
        "# Usaremos una distribución exponencial para que no sea normal y vean el poder de la LGN y el TCL\n",
        "# La media de una distribución exponencial con escala beta es beta.\n",
        "# Aquí, usaremos una escala de 50000, así que la media poblacional es 50000.\n",
        "poblacion = np.random.exponential(scale=50000, size=1000000)\n",
        "mu_poblacional = np.mean(poblacion) # Calculamos la media real de nuestra gran población simulada\n",
        "\n",
        "print(f\"Media real de la población (parámetro): ${mu_poblacional:.2f}\")\n",
        "\n",
        "# Añadimos la gráfica de la población para mostrar que no es normal\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(poblacion, bins=50, density=True, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "plt.title('Distribución de la Población (Exponencial)')\n",
        "plt.xlabel('Ingresos')\n",
        "plt.ylabel('Densidad')\n",
        "plt.grid(True, which=\"both\", ls=\"--\", c='0.7')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LFsQ4vLzaJ0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tamaños de muestra a probar\n",
        "tamanios_muestra = [5, 10, 20, 50, 100, 200, 500, 1000, 2000, 5000, 10000]\n",
        "medias_muestrales = []\n",
        "\n",
        "# Tomamos una muestra de cada tamaño y calculamos su media\n",
        "for n in tamanios_muestra:\n",
        "    muestra = np.random.choice(poblacion, size=n, replace=False) # replace=False para muestreo sin reemplazo\n",
        "    medias_muestrales.append(np.mean(muestra))\n",
        "\n",
        "# Visualizamos la convergencia\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(tamanios_muestra, medias_muestrales, 'o-', label='Media muestral')\n",
        "plt.axhline(y=mu_poblacional, color='r', linestyle='--', label='Media poblacional real ($\\mu$)')\n",
        "plt.xlabel('Tamaño de la Muestra ($n$)')\n",
        "plt.ylabel('Media del Ingreso')\n",
        "plt.title('Convergencia de la Media Muestral a la Media Poblacional (Ley de los Grandes Números)')\n",
        "plt.xscale('log') # Escala logarítmica para ver mejor la convergencia en diferentes órdenes de magnitud\n",
        "plt.legend()\n",
        "plt.grid(True, which=\"both\", ls=\"--\", c='0.7')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BEVMPEmQ7EMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reflexión:** Como pueden observar en la gráfica, al principio, con muestras pequeñas, la media muestral puede estar bastante alejada de la media poblacional real. Pero a medida que aumentamos el tamaño de la muestra, los puntos de la media muestral se \"concentran\" alrededor de la línea roja, que representa la media poblacional. Esto nos da la primera gran razón por la que el muestreo funciona: **muestras más grandes tienden a ser más representativas de la población**.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. El Teorema Central del Límite: La Forma de la Distribución de las Medias Muestrales**\n",
        "\n",
        "Ahora bien, la Ley de los Grandes Números es genial para entender que una *única* muestra grande es buena. Pero, ¿qué pasa si tomamos *múltiples* muestras? ¿Cómo se distribuyen los estadísticos que obtenemos de esas múltiples muestras? Aquí es donde el **Teorema Central del Límite (TCL)** brilla con luz propia, y es, sin duda, \"el teorema más importante de la estadística\". Sin él, la inferencia estadística sería \"imposible\".\n",
        "\n",
        "Mientras la Ley de los Grandes Números se centra en el *tamaño de una sola muestra*, el TCL se enfoca en el **número de muestras** que obtenemos.\n",
        "\n",
        "El TCL establece que:\n",
        "\n",
        "1.  Si tomamos un **número suficientemente grande de muestras** de una población (sin importar cuál sea la distribución de esa población).\n",
        "2.  Y calculamos un estadístico (como la media o la suma) para cada una de esas muestras.\n",
        "3.  Entonces, la **distribución de esos estadísticos muestrales se aproximará a una distribución normal (campana de Gauss)**.\n",
        "\n",
        "Esto es asombroso porque significa que, incluso si nuestra población original no sigue una distribución normal (¡como nuestro ejemplo de ingresos exponenciales!), las medias de las muestras que tomemos de esa población sí tenderán a distribuirse normalmente. Esta propiedad es fundamental para utilizar todas las herramientas poderosas de la distribución normal en nuestro análisis.\n",
        "\n",
        "#### **Parámetros de la Distribución Muestral de la Media**\n",
        "\n",
        "Cuando hablamos de la distribución de las medias muestrales, esta distribución también tiene su propia media y desviación estándar:\n",
        "\n",
        "*   **Media de las medias muestrales ($E(\\bar{X})$):** Es igual a la media de la población original ($\\mu$).\n",
        "\n",
        "    $E(\\bar{X}) = \\mu$\n",
        "\n",
        "*   **Desviación estándar de las medias muestrales ($\\sigma_{\\bar{X}}$), también conocida como Error Estándar:** Es igual a la desviación estándar de la población ($\\sigma$) dividida por la raíz cuadrada del tamaño de la muestra ($n$).\n",
        "\n",
        "    $\\sigma_{\\bar{X}} = \\frac{\\sigma}{\\sqrt{n}}$\n",
        "\n",
        "Y para poder usar las tablas de la distribución normal estándar (o $Z$-score), podemos **tipificar** la media muestral:\n",
        "\n",
        "$Z = \\frac{\\bar{X} - \\mu}{\\sigma/\\sqrt{n}}$\n",
        "\n",
        "#### **Simulación 2: La Distribución de Medias Muestrales Tiende a la Normal**\n",
        "\n",
        "Vamos a tomar nuestra población de ingresos con distribución exponencial (que no es normal) y veamos cómo se comportan las medias de muchas muestras de un tamaño fijo."
      ],
      "metadata": {
        "id": "VMcbo3c67rYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Población original (exponencial, no normal)\n",
        "poblacion = np.random.exponential(scale=50000, size=1000000)\n",
        "mu_poblacional = np.mean(poblacion)\n",
        "sigma_poblacional = np.std(poblacion)\n",
        "\n",
        "display(Markdown(f\"Media real de la población ($\\mu$): ${mu_poblacional:.2f}\"))\n",
        "display(Markdown(f\"Desviación estándar real de la población ($\\sigma$): ${sigma_poblacional:.2f}\\n\"))\n",
        "\n",
        "# Número de muestras a tomar\n",
        "num_muestras = 5000\n",
        "# Tamaño de cada muestra (debe ser \"suficientemente grande\" para el TCL, típicamente >= 30)\n",
        "tamano_muestra_clt = 30\n",
        "\n",
        "medias_de_muestras = []\n",
        "\n",
        "for _ in range(num_muestras):\n",
        "    muestra = np.random.choice(poblacion, size=tamano_muestra_clt, replace=False)\n",
        "    medias_de_muestras.append(np.mean(muestra))\n",
        "\n"
      ],
      "metadata": {
        "id": "fiFommCj8XON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculamos la media y desviación estándar de las medias muestrales obtenidas\n",
        "media_de_las_medias = np.mean(medias_de_muestras)\n",
        "std_dev_de_las_medias = np.std(medias_de_muestras)\n",
        "\n",
        "# Verificamos los parámetros esperados por el TCL\n",
        "expected_std_dev = sigma_poblacional / np.sqrt(tamano_muestra_clt)\n",
        "\n",
        "display(Markdown(f\"Media de las medias muestrales ($E(\\\\bar{{X}})$): ${media_de_las_medias:.2f}\"))\n",
        "display(Markdown(f\"Desviación estándar de las medias muestrales ($\\sigma_{{\\\\bar{{X}}}}$): ${std_dev_de_las_medias:.2f}\"))\n",
        "display(Markdown(f\"Error estándar esperado por TCL ($\\sigma / \\sqrt{{n}}$): ${expected_std_dev:.2f}\"))\n",
        "\n",
        "# Visualizamos el histograma de las medias muestrales\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(medias_de_muestras, kde=True, bins=50, color='skyblue', edgecolor='black')\n",
        "plt.axvline(x=mu_poblacional, color='red', linestyle='--', label=f'Media poblacional ($\\mu$): ${mu_poblacional:.2f}$')\n",
        "plt.axvline(x=media_de_las_medias, color='green', linestyle=':', label=f'Media de medias muestrales: ${media_de_las_medias:.2f}$')\n",
        "plt.title(f'Distribución de {num_muestras} Medias Muestrales (n={tamano_muestra_clt})')\n",
        "plt.xlabel('Media de las Muestras')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "S1NdYwX_Fe16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Reflexión:** ¡Miren esa campana de Gauss emergiendo! A pesar de que nuestra población original (ingresos) era exponencial y sesgada, el histograma de las *medias de las muestras* se ve claramente normal. Además, la media de todas esas medias muestrales está muy cerca de la media poblacional real, y su desviación estándar (el error estándar) es muy cercana a la que predice el TCL ($\\sigma / \\sqrt{n}$).\n",
        "\n",
        "#### **Simulación 3: El efecto del tamaño de muestra ($n$) en la forma normal (CLT)**\n",
        "\n",
        "El TCL nos dice que la distribución de las medias muestrales se vuelve normal cuando $n$ es \"suficientemente grande\". Pero, ¿qué significa \"suficientemente grande\"? Aunque algunos textos sugieren $n > 30$ como una regla práctica, la velocidad de convergencia a la normalidad depende de la distribución original de la población. Para distribuciones muy asimétricas, podríamos necesitar una $n$ mucho mayor.\n",
        "\n",
        "Vamos a observar cómo cambia la distribución de las medias muestrales para diferentes tamaños de $n$.\n"
      ],
      "metadata": {
        "id": "oC5Qu9dvA61p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Población original (exponencial, no normal)\n",
        "poblacion = np.random.exponential(scale=50000, size=1000000)\n",
        "mu_poblacional = np.mean(poblacion)\n",
        "\n",
        "# Tamaños de muestra para comparar\n",
        "n_values = [5, 10, 20, 50, 100, 200]\n",
        "num_muestras_per_n = 800 # Un número elevado de muestras para ver bien la distribución\n",
        "\n",
        "# Calculate the number of rows and columns for the subplots\n",
        "n_cols = 3\n",
        "n_rows = (len(n_values) + n_cols - 1) // n_cols\n",
        "\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(14, n_rows * 3))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, n in enumerate(n_values):\n",
        "    medias_temp = []\n",
        "    for _ in range(num_muestras_per_n):\n",
        "        muestra = np.random.choice(poblacion, size=n, replace=False)\n",
        "        medias_temp.append(np.mean(muestra))\n",
        "\n",
        "    sns.histplot(medias_temp, kde=True, bins=50, ax=axes[i], color='lightcoral', edgecolor='black')\n",
        "    axes[i].axvline(x=mu_poblacional, color='blue', linestyle='--', label='Media poblacional ($\\mu$)')\n",
        "    axes[i].set_title(f'Distribución de Medias Muestrales (n={n})')\n",
        "    axes[i].set_xlabel('Media de las Muestras')\n",
        "    axes[i].set_ylabel('Frecuencia')\n",
        "    axes[i].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Convergencia a la Normalidad con el Teorema Central del Límite', y=1.02, fontsize=18)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0tHuH_i_A98x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reflexión:** Esta es la clave del TCL. Observen cómo, incluso con una población inicial muy sesgada (exponencial), a medida que el tamaño de la muestra ($n$) aumenta, la distribución de las medias muestrales se vuelve más y más simétrica y con forma de campana (normal). Para $n=5$, todavía vemos algo de sesgo, pero para $n=30$ o $n=100$, ¡es una distribución normal muy clara! Esto nos permite decir que, **para una $n$ suficientemente grande, podemos asumir que la distribución de las medias de nuestras muestras es normal**, lo cual es una base sólida para la inferencia.\n",
        "\n",
        "#### **Simulación 4: ¿Y si la población original ya es normal?**\n",
        "\n",
        "¿Qué pasa si la población de donde tomamos las muestras ya tiene una distribución normal? El TCL sigue aplicando, pero la convergencia es casi instantánea."
      ],
      "metadata": {
        "id": "3HgUV97gBVtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Población original (normal)\n",
        "poblacion_normal = np.random.normal(loc=100, scale=15, size=1000000) # Media 100, Desviación Estándar 15\n",
        "mu_poblacional_normal = np.mean(poblacion_normal)\n",
        "\n",
        "# Tamaños de muestra para comparar\n",
        "n_values_normal = [10, 30,50, 70] # Tamaños más pequeños para apreciar el efecto\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, n in enumerate(n_values_normal):\n",
        "    medias_temp = []\n",
        "    for _ in range(num_muestras_per_n):\n",
        "        muestra = np.random.choice(poblacion_normal, size=n, replace=False)\n",
        "        medias_temp.append(np.mean(muestra))\n",
        "\n",
        "    sns.histplot(medias_temp, kde=True, bins=50, ax=axes[i], color='lightgreen', edgecolor='black')\n",
        "    axes[i].axvline(x=mu_poblacional_normal, color='blue', linestyle='--', label='Media poblacional ($\\mu$)')\n",
        "    axes[i].set_title(f'Distribución de Medias Muestrales (n={n}) - Población Normal')\n",
        "    axes[i].set_xlabel('Media de las Muestras')\n",
        "    axes[i].set_ylabel('Frecuencia')\n",
        "    axes[i].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Convergencia a la Normalidad con el Teorema Central del Límite (Población Normal)', y=1.02, fontsize=18)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fYLA_DJ_Bhco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reflexión:** Si la población ya es normal, la distribución de las medias muestrales será normal para cualquier tamaño de muestra $n$, incluso para $n$ muy pequeños. El TCL es aún más potente porque nos asegura que esta normalidad se mantiene o se alcanza rápidamente.\n",
        "\n",
        "---\n",
        "\n",
        "### **4. ¿Por qué funciona el muestreo aleatorio y su conexión con el TCL?**\n",
        "\n",
        "Ahora unamos todas las piezas:\n",
        "\n",
        "1.  **La LGN nos dice que una muestra grande es probablemente muy similar a la población en términos de un estadístico (como la media)**. Esto ya nos da confianza en que nuestra estimación es \"cercana\" al valor real.\n",
        "2.  **El TCL nos da una caracterización matemática de *cómo* se comportan esas estimaciones si repitiéramos el muestreo muchas veces**. Nos dice que la distribución de estas estimaciones es normal, y nos da sus parámetros (media y error estándar).\n",
        "\n",
        "La combinación de la Ley de los Grandes Números y el Teorema Central del Límite es lo que da la base científica y matemática al muestreo aleatorio.\n",
        "\n",
        "*   **Sin el muestreo aleatorio,** estos teoremas no se cumplirían. Si no seleccionamos las muestras de forma aleatoria (por ejemplo, solo encuestamos a las personas más fáciles de encontrar, lo que se conoce como muestreo por conveniencia o no probabilístico), introducimos **sesgos**. Los sesgos significan que nuestra muestra no es representativa, y entonces los estadísticos que obtenemos de ella no se acercarán al parámetro poblacional de forma predecible, y su distribución no será necesariamente normal, invalidando el uso del TCL y, por ende, de la inferencia estadística.\n",
        "*   **El muestreo aleatorio** (como el aleatorio simple, sistemático o estratificado) asegura que cada elemento de la población tenga una probabilidad conocida (y no nula) de ser seleccionado, minimizando así el sesgo y permitiendo que la LGN y el TCL entren en acción. Es este carácter aleatorio el que permite que las propiedades teóricas de la probabilidad se apliquen a lo que observamos en la práctica.\n",
        "\n",
        "En esencia, el muestreo aleatorio funciona porque, gracias a estos teoremas fundamentales, podemos:\n",
        "\n",
        "*   **Conocer la variabilidad de nuestras estimaciones:** El error estándar ($\\sigma_{\\bar{X}} = \\frac{\\sigma}{\\sqrt{n}}$) nos dice cuánto \"ruido\" o variabilidad hay en nuestras medias muestrales. Cuanto más grande sea la muestra, menor será este error estándar, lo que significa que nuestras estimaciones son más precisas.\n",
        "*   **Cuantificar la incertidumbre:** Sabiendo que la distribución de las medias muestrales es normal, podemos calcular probabilidades sobre dónde se encuentra el verdadero parámetro poblacional. Esto es lo que nos permite construir **intervalos de confianza** y realizar **pruebas de hipótesis**.\n",
        "\n",
        "---\n",
        "\n",
        "### **5. Hacia la Inferencia Estadística: El Camino por Delante**\n",
        "\n",
        "Estimados estudiantes, lo que hemos visto hoy es la piedra angular de gran parte de la Ciencia de Datos y la estadística. La comprensión profunda de por qué el muestreo funciona y cómo el Teorema Central del Límite nos regala la normalidad en la distribución de las medias muestrales, es el trampolín para los siguientes temas cruciales:\n",
        "\n",
        "*   **Intervalos de Confianza:** Una vez que sabemos que la media de nuestras muestras se distribuye normalmente alrededor de la media poblacional, podemos construir un rango de valores (un intervalo) dentro del cual esperamos que se encuentre el verdadero parámetro poblacional con un cierto nivel de confianza (por ejemplo, 95% o 99%). Esto es muchísimo más útil que dar una sola estimación puntual.\n",
        "*   **Pruebas de Hipótesis:** Con la distribución normal de las medias muestrales bajo el brazo, podemos formular hipótesis sobre los parámetros de la población y usar los datos de nuestra muestra para decidir si tenemos suficiente evidencia para \"rechazar\" o \"no rechazar\" esas hipótesis. Por ejemplo, ¿el nuevo medicamento realmente reduce la glucosa en sangre?\n",
        "\n",
        "El Teorema Central del Límite nos traslada del \"mundo de la estadística\" (donde solo conocemos lo de la muestra) al \"mundo de la probabilidad\" (donde conocemos la distribución de la que proviene la media muestral), permitiéndonos hacer inferencias robustas sobre la población.\n",
        "\n",
        "Espero que esta explicación y las simulaciones les hayan encendido una chispa de intuición sobre estos conceptos tan vitales. En las próximas clases, construiremos sobre esta base para domar los intervalos de confianza y las pruebas de hipótesis, herramientas esenciales en el arsenal de cualquier Científico de Datos.\n",
        "\n",
        "¡Nos vemos en la siguiente clase, donde profundizaremos aún más en cómo aplicar todo esto!"
      ],
      "metadata": {
        "id": "to3RlPfe55Np"
      }
    }
  ]
}