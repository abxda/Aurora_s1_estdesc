{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsm6PRDqX1vOGtsIvqt8X5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abxda/Aurora_s1_estdesc/blob/main/Semana_2_Aurora_EstDesc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Intervalos de Confianza**\n",
        "\n",
        "El estudio de los intervalos de confianza es fundamental en Ciencia de Datos, ya que nos permite ir más allá de una simple estimación puntual y cuantificar la incertidumbre de nuestras predicciones sobre una población basándonos en una muestra. ¡Es como ponerle un \"rango de confianza\" a nuestras afirmaciones!\n",
        "\n",
        "#### **1. Generalidades de Intervalos de Confianza**\n",
        "\n",
        "**1.1. Distribución de Muestreo de la Media**\n",
        "\n",
        "Mis queridos estudiantes, la **distribución de muestreo** es un concepto teórico pero de una utilidad práctica inmensa. Imaginen que tenemos una población, por ejemplo, todas las estaturas de los habitantes de la Ciudad de México. Nosotros, como buenos científicos de datos, sabemos que es prácticamente imposible medir a cada persona. Así que, ¿qué hacemos? Tomamos una **muestra** de esa población y calculamos un **estadístico**, como la media de las estaturas en nuestra muestra.\n",
        "\n",
        "Ahora, si tomamos *otra* muestra diferente de la misma población, es muy probable que su media sea ligeramente distinta. ¡Y si tomamos muchas muestras, obtendremos muchas medias muestrales diferentes! La genialidad aquí es que, si tratamos cada una de estas medias muestrales como una **única observación**, podemos construir una nueva distribución: la **distribución de muestreo de la media**.\n",
        "\n",
        "Esta distribución nos responde una pregunta clave: **¿de qué distribución proviene la media de una muestra?**. Es decir, nos permite pasar del mundo de lo que conocemos (nuestra muestra) al mundo de la probabilidad, donde podemos hacer inferencias sobre la población completa. Es la base para la estimación puntual, los intervalos de confianza y las pruebas de hipótesis.\n",
        "\n",
        "**Para alimentar la intuición con una simulación en Python:**\n",
        "Podríamos crear una población sintética (por ejemplo, 100,000 puntos de datos) con una distribución conocida (quizás una distribución uniforme o exponencial, que no son normales).\n",
        "\n",
        "1.  **Población:** Generamos y visualizamos la distribución de nuestra población.\n",
        "    *   `np.random.rand(100000)` (uniforme)\n",
        "    *   `np.random.exponential(scale=10, size=100000)` (exponencial)\n",
        "2.  **Parámetro N (tamaño de muestra) controlable:** Permita al usuario elegir un tamaño de muestra $n$ (ej., 5, 10, 30, 100).\n",
        "3.  **Bucle de muestreo:** Repetidamente, extraemos $M$ muestras (ej., 1000, 10000) de tamaño $n$ de la población. Para cada muestra, calculamos su media.\n",
        "4.  **Histograma dinámico:** Graficamos el histograma de estas $M$ medias muestrales. Permita ver cómo la forma de este histograma evoluciona a medida que se recolectan más muestras.\n",
        "\n",
        "Este ejercicio les permitirá ver cómo, incluso si la población original no es normal, el histograma de las medias muestrales comienza a adquirir una forma de campana.\n",
        "\n",
        "**1.2. El Error Estándar de la Media**\n",
        "\n",
        "¡Ah, el **error estándar de la media (SEM)**! Es un concepto que, si lo dominan, les dará una gran ventaja en el análisis de datos. Piensen en él como la **desviación estándar de nuestra distribución de muestreo de la media**. Mientras que la desviación estándar de la población ($\\sigma$) nos dice qué tan dispersos están los datos individuales, el error estándar de la media nos dice qué tan dispersas están las *medias de nuestras muestras* alrededor de la verdadera media poblacional ($\\mu$).\n",
        "\n",
        "Dicho de otra forma, es una medida de la **precisión** con la que la media de nuestra muestra individual estima la media real de la población. Un SEM pequeño significa que nuestras medias muestrales (y, por lo tanto, nuestra estimación) están muy cerca unas de otras y, presumiblemente, cerca de la media poblacional.\n",
        "\n",
        "Su fórmula, para una población con desviación estándar $\\sigma$ y muestras de tamaño $n$, es:\n",
        "$$SEM = \\frac{\\sigma}{\\sqrt{n}}$$\n",
        "\n",
        "Si no conocemos la desviación estándar de la población ($\\sigma$), podemos estimarla utilizando la desviación estándar de nuestra muestra ($s$):\n",
        "$$SEM \\approx \\frac{s}{\\sqrt{n}}$$\n",
        "\n",
        "Noten la importancia de $n$: **cuanto mayor sea el tamaño de la muestra ($n$), menor será el error estándar de la media**. Esto tiene mucho sentido, ¿verdad? Si nuestra muestra es más grande, es más representativa de la población, y su media será una estimación más precisa. Sin embargo, para tamaños de muestra pequeños, la desviación estándar (y por ende el SEM) tiende a ser más variable y menos fiable.\n",
        "\n",
        "**Para alimentar la intuición con una simulación en Python (continuando con la anterior):**\n",
        "\n",
        "1.  **Calcula y muestra el SEM empírico:** En el bucle de muestreo, calcula la desviación estándar de todas las medias muestrales recolectadas hasta el momento.\n",
        "2.  **Compara con el SEM teórico:** Si la población sintética tiene una $\\sigma$ conocida, muestra el valor teórico de $SEM = \\sigma / \\sqrt{n}$. Observen cómo el SEM empírico se acerca al teórico a medida que aumentan las simulaciones.\n",
        "3.  **Impacto del tamaño de muestra:** Al cambiar el $n$ (tamaño de cada muestra), observen cómo el histograma de las medias se hace más estrecho y alto, lo que visualiza una menor dispersión y, por lo tanto, un menor SEM.\n",
        "\n",
        "**1.3. El Teorema del Límite Central (TLC)**\n",
        "\n",
        "¡El **Teorema del Límite Central (TLC)** es la joya de la corona de la estadística inferencial! Suena complejo, pero es increíblemente intuitivo una vez que lo visualizan. Este teorema establece que, si tomamos un **número suficientemente grande de muestras** de una población (¡cualquiera que sea su distribución original!), la distribución de las **medias (o sumas) de esas muestras se aproximará a una distribución normal**.\n",
        "\n",
        "¿Entienden la magnitud de esto? Significa que no importa si la altura de las personas en una ciudad no sigue una distribución normal, o si el tiempo que tarda un servidor en responder no es normal. Si tomamos suficientes muestras de estas mediciones y calculamos sus medias, esas medias ¡sí se comportarán de forma normal! Esto es muy importante porque la distribución normal tiene propiedades maravillosas que nos permiten hacer muchas inferencias estadísticas.\n",
        "\n",
        "**Principios clave del TLC:**\n",
        "*   **Independencia de las variables aleatorias:** Las variables de las que tomamos muestras deben ser independientes entre sí.\n",
        "*   **Tamaño de muestra \"suficientemente grande\":** Este es el punto clave. A medida que $n$ (el tamaño de *cada* muestra) aumenta, la distribución de las medias se vuelve más normal y más precisa. Aunque algunos textos sugieren $n > 30$ como una regla general, la rapidez de esta convergencia puede depender de la forma de la distribución original y sus parámetros. Por ejemplo, para una distribución binomial, la aproximación es buena si $np \\ge 10$ y $n(1-p) \\ge 10$.\n",
        "*   **Forma original de la distribución:** ¡Esto es lo sorprendente! La forma de la distribución de la población original no importa. El TLC nos garantiza la normalidad de las medias muestrales.\n",
        "\n",
        "**Formalmente, para una secuencia de variables aleatorias independientes e idénticamente distribuidas (i.i.d.) $\\{X_1, X_2, \\dots, X_n\\}$ con media $\\mu$ y varianza $\\sigma^2$, si definimos la media muestral como $\\bar{X} = \\frac{1}{n}\\sum_{i=1}^n X_i$, entonces cuando $n$ tiende a infinito, la distribución de $\\frac{\\sqrt{n}(\\bar{X} - \\mu)}{\\sigma}$ converge a una distribución normal estándar $N(0,1)$**.\n",
        "\n"
      ],
      "metadata": {
        "id": "orGynpTnpBcB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Distribución de Muestreo y el Teorema del Límite Central (TLC)**\n",
        "\n",
        "Vamos a combinar los puntos 1.1, 1.2 y 1.3 en una única y poderosa simulación. Esta visualización es la piedra angular de la inferencia. Mostraremos cómo la distribución de las medias muestrales tiende a la normalidad, sin importar la forma de la población original, y cómo el Error Estándar (SEM) define su dispersión.\n",
        "\n",
        "#### **Simulación Interactiva: El Teorema del Límite Central en Acción**\n",
        "\n",
        "Esta simulación les permitirá:\n",
        "1.  Elegir una distribución de población (algunas muy \"no-normales\").\n",
        "2.  Controlar el tamaño de cada muestra (`n`).\n",
        "3.  Controlar el número de muestras que tomamos (`M`).\n",
        "4.  Observar en tiempo real cómo la distribución de las medias muestrales (derecha) se transforma en una campana de Gauss, mientras la población original (izquierda) permanece igual.\n"
      ],
      "metadata": {
        "id": "4TyJyY_Jrals"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar las librerías necesarias\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import interact, IntSlider, Dropdown\n",
        "from scipy.stats import norm, expon, uniform\n",
        "\n",
        "# Estilo de gráficos más agradable\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# --- Función Principal de la Simulación del TLC ---\n",
        "def simular_tlc(distribucion='Exponencial', tamano_muestra=30, num_muestras=1000):\n",
        "    \"\"\"\n",
        "    Función interactiva para visualizar el Teorema del Límite Central.\n",
        "    \"\"\"\n",
        "    # 1. Crear la población base\n",
        "    tamano_poblacion = 100000\n",
        "    if distribucion == 'Exponencial':\n",
        "        # Una distribución muy sesgada a la derecha\n",
        "        poblacion = np.random.exponential(scale=20, size=tamano_poblacion)\n",
        "        pop_mean = 20\n",
        "        pop_std = 20\n",
        "    elif distribucion == 'Uniforme':\n",
        "        # Perfectamente plana, nada de normal\n",
        "        poblacion = np.random.uniform(0, 100, size=tamano_poblacion)\n",
        "        pop_mean = 50\n",
        "        pop_std = np.sqrt(((100-0)**2)/12)\n",
        "    elif distribucion == 'Bimodal':\n",
        "        # Dos picos, claramente no normal\n",
        "        poblacion1 = np.random.normal(25, 5, tamano_poblacion // 2)\n",
        "        poblacion2 = np.random.normal(75, 5, tamano_poblacion // 2)\n",
        "        poblacion = np.concatenate([poblacion1, poblacion2])\n",
        "        pop_mean = np.mean(poblacion)\n",
        "        pop_std = np.std(poblacion)\n",
        "    else: # Normal\n",
        "        poblacion = np.random.normal(50, 15, size=tamano_poblacion)\n",
        "        pop_mean = 50\n",
        "        pop_std = 15\n",
        "\n",
        "    # 2. Tomar 'num_muestras' muestras y calcular sus medias\n",
        "    medias_muestrales = []\n",
        "    for _ in range(num_muestras):\n",
        "        muestra = np.random.choice(poblacion, size=tamano_muestra)\n",
        "        medias_muestrales.append(np.mean(muestra))\n",
        "\n",
        "    # 3. Preparar la visualización\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "    # Gráfico 1: Distribución de la Población Original\n",
        "    sns.histplot(poblacion, kde=True, ax=ax1, color='skyblue')\n",
        "    ax1.set_title(f'Distribución de la Población\\n(Tipo: {distribucion})')\n",
        "    ax1.axvline(pop_mean, color='red', linestyle='--', label=f'Media Poblacional (μ) = {pop_mean:.2f}')\n",
        "    ax1.legend()\n",
        "    ax1.set_xlabel(\"Valor\")\n",
        "    ax1.set_ylabel(\"Frecuencia\")\n",
        "\n",
        "    # Gráfico 2: Distribución de las Medias Muestrales\n",
        "    sns.histplot(medias_muestrales, kde=True, ax=ax2, color='salmon')\n",
        "\n",
        "    # Superponer la curva normal teórica predicha por el TLC\n",
        "    sem_teorico = pop_std / np.sqrt(tamano_muestra)\n",
        "    x = np.linspace(pop_mean - 4*sem_teorico, pop_mean + 4*sem_teorico, 100)\n",
        "    pdf_normal = norm.pdf(x, loc=pop_mean, scale=sem_teorico)\n",
        "    ax2.plot(x, pdf_normal, 'k--', linewidth=2, label='Curva Normal Teórica (TLC)')\n",
        "\n",
        "    # Calcular media y SEM empíricos\n",
        "    mean_de_medias = np.mean(medias_muestrales)\n",
        "    sem_empirico = np.std(medias_muestrales)\n",
        "\n",
        "    ax2.axvline(mean_de_medias, color='blue', linestyle='--', label=f'Media de las medias = {mean_de_medias:.2f}')\n",
        "    ax2.set_title(f'Distribución de {num_muestras} Medias Muestrales (n={tamano_muestra})')\n",
        "    ax2.set_xlabel(\"Media Muestral\")\n",
        "    ax2.legend()\n",
        "\n",
        "    plt.suptitle(f'Error Estándar Teórico (SEM): {sem_teorico:.2f} | SEM Empírico: {sem_empirico:.2f}', fontsize=14)\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "    plt.show()\n",
        "\n",
        "# --- Crear los controles interactivos ---\n",
        "interact(simular_tlc,\n",
        "         distribucion=Dropdown(options=['Exponencial', 'Uniforme', 'Bimodal', 'Normal'], value='Exponencial'),\n",
        "         tamano_muestra=IntSlider(min=2, max=500, step=1, value=30, description='Tamaño Muestra (n)'),\n",
        "         num_muestras=IntSlider(min=10, max=10000, step=10, value=1000, description='Nº de Muestras (M)'));"
      ],
      "metadata": {
        "id": "pe8tXSwIpBkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Guía para el Estudiante (qué observar en la simulación):**\n",
        "\n",
        "1.  **El poder del TLC:** Empieza con la distribución `Exponencial` (muy asimétrica). Fija `n=2`. El gráfico de la derecha (distribución de medias) también se verá asimétrico. Ahora, **aumenta lentamente el `tamaño_muestra (n)`**. Observa cómo, mágicamente, el histograma de la derecha se va transformando en una campana simétrica, ¡incluso cuando la población original sigue siendo exponencial! La regla `n > 30` es una buena guía; verás una clara forma de campana a partir de ahí.\n",
        "2.  **El Error Estándar (SEM):** Mantén `n` fijo (ej. `n=50`). Observa el valor del \"Error Estándar Teórico\". Ahora, mira el histograma de la derecha. Ese valor del SEM es la desviación estándar de *ese* histograma. **Aumenta `n` a `200`**. Verás que el SEM disminuye drásticamente y el histograma se vuelve mucho más alto y estrecho. Esto visualiza la fórmula $SEM = \\sigma / \\sqrt{n}$: a mayor `n`, menor dispersión de las medias muestrales, lo que significa estimaciones más precisas.\n",
        "3.  **Convergencia:** El \"SEM Empírico\" es la desviación estándar que calculamos de nuestras simulaciones. El \"SEM Teórico\" es el valor matemático. Aumenta el `Nº de Muestras (M)` a 10,000. Verás que el valor empírico se acerca cada vez más al teórico. Esto demuestra que la teoría funciona en la práctica.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "mnLg0F7wsSH5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2. El Proceso de Inferencia Estadística para un Parámetro**\n",
        "\n",
        "La inferencia estadística es la rama de la estadística que nos permite sacar conclusiones y hacer generalizaciones sobre una población más grande utilizando únicamente la información de una muestra representativa.\n",
        "\n",
        "**2.1. Las Características de un Estimador**\n",
        "\n",
        "Un **estimador** es simplemente una función de los datos que observamos en nuestra muestra que usamos para \"adivinar\" o inferir el valor de un **parámetro poblacional**. Por ejemplo, la media muestral ($\\bar{X}$) es un estimador de la media poblacional ($\\mu$), y la proporción muestral ($\\hat{p}$) es un estimador de la proporción poblacional ($p$).\n",
        "\n",
        "Las características deseables de un buen estimador incluyen:\n",
        "*   **Insesgamiento (Unbiasedness):** Un estimador es insesgado si su valor esperado (el promedio de todas las posibles estimaciones que obtendríamos si repitiéramos el muestreo infinitas veces) es igual al verdadero valor del parámetro poblacional. La media muestral es un estimador insesgado de la media poblacional.\n",
        "*   **Eficiencia:** Un estimador es más eficiente si tiene una menor varianza (o menor error estándar) entre sus posibles valores, lo que significa que sus estimaciones están más \"apretadas\" alrededor del valor verdadero. Esto se relaciona directamente con el tamaño de la muestra; una muestra más grande generalmente conduce a estimadores más eficientes.\n",
        "*   **Consistencia:** A medida que el tamaño de la muestra aumenta, el estimador se acerca más al verdadero valor del parámetro. La Ley de los Grandes Números es un ejemplo de este principio, afirmando que la media muestral converge al valor esperado de la variable a medida que $n$ aumenta.\n",
        "*   **Representatividad:** Una muestra debe ser cuidadosamente seleccionada para reflejar las proporciones y características de la población total.\n",
        "\n",
        "**Para alimentar la intuición con una simulación en Python:**\n",
        "\n",
        "1.  **Población con Parámetro Conocido:** Definir una población donde conozcamos el verdadero valor del parámetro (e.g., media $\\mu$, proporción $p$).\n",
        "2.  **Muestreo Repetitivo:** Tomar un gran número de muestras.\n",
        "3.  **Cálculo del Estimador:** Para cada muestra, calcular el estimador (e.g., media muestral $\\bar{X}$).\n",
        "4.  **Visualización de la Distribución del Estimador:** Crear un histograma de los valores del estimador.\n",
        "5.  **Comparación:** Mostrar la media de este histograma y compararla con el valor verdadero del parámetro. Verán cómo la media de los estimadores se acerca al parámetro poblacional, demostrando el insesgamiento.\n",
        "\n",
        "**2.2. Estimación de un Promedio Poblacional**\n",
        "\n",
        "Cuando queremos estimar la media de una población ($\\mu$) a partir de una muestra, utilizamos la **media muestral** ($\\bar{X}$) como nuestro **estimador puntual**. Este es el valor más probable para el parámetro que deseamos estimar, basado en nuestros datos de muestra.\n",
        "\n",
        "**La fórmula de la media muestral es simplemente el promedio de los valores en su muestra:**\n",
        "$$\\bar{X} = \\frac{\\sum_{i=1}^n X_i}{n}$$\n",
        "Donde $X_i$ son los valores individuales de la muestra y $n$ es el tamaño de la muestra.\n",
        "\n",
        "**Para alimentar la intuición con una simulación en Python:**\n",
        "\n",
        "1.  **Población:** Generar una población (por ejemplo, edades de personas).\n",
        "2.  **Muestra:** Permitir al usuario extraer una muestra de tamaño $n$.\n",
        "3.  **Cálculo:** Calcular y mostrar la media de esta muestra.\n",
        "4.  **Estimación Visual:** Colocar esta media muestral en un gráfico de la población, mostrando que es nuestra \"mejor suposición\" de dónde se encuentra la verdadera media poblacional.\n",
        "\n",
        "**2.3. Estimación de una Proporción Poblacional**\n",
        "\n",
        "De manera similar a la media, si nuestra variable de interés es categórica (por ejemplo, la proporción de estudiantes que usan lentes en la universidad), usamos la **proporción muestral** ($\\hat{p}$) como nuestro estimador puntual para la proporción poblacional ($p$).\n",
        "\n",
        "**La fórmula de la proporción muestral es:**\n",
        "$$\\hat{p} = \\frac{\\text{Número de elementos con la característica deseada}}{\\text{Tamaño de la muestra}}$$\n",
        "\n",
        "**Para alimentar la intuición con una simulación en Python:**\n",
        "\n",
        "1.  **Población Categórica:** Crear una población con una proporción conocida de una característica (ej., un arreglo de 0s y 1s).\n",
        "2.  **Muestra:** Permitir al usuario extraer una muestra de tamaño $n$.\n",
        "3.  **Cálculo:** Calcular y mostrar la proporción de la característica en esta muestra.\n",
        "4.  **Estimación Visual:** Mostrar cómo $\\hat{p}$ se acerca a $p$ a medida que $n$ aumenta."
      ],
      "metadata": {
        "id": "BxI5X6QLpJwx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Crearemos dos simulaciones principales:\n",
        "\n",
        "1.  **La primera simulación se enfocará en el punto 2.1**, que es el más teórico. Visualizaremos las propiedades de un estimador (insesgamiento, eficiencia, consistencia) tomando miles de muestras y observando el comportamiento agregado de los estimadores.\n",
        "2.  **La segunda simulación se enfocará en los puntos 2.2 y 2.3**, mostrando el acto práctico de tomar *una sola muestra* y calcular un estimador puntual como nuestra \"mejor suposición\" del parámetro real.\n",
        "\n",
        "### **Simulación 1: Explorando las Características de un Buen Estimador**\n",
        "\n",
        "Esta simulación es el corazón del concepto. Demostraremos visualmente por qué la media muestral ($\\bar{X}$) es un estimador tan valioso.\n",
        "\n",
        "**Objetivos de la Simulación:**\n",
        "*   **Insesgamiento (Unbiasedness):** Veremos que, en promedio, el estimador ($\\bar{X}$) acierta perfectamente al parámetro verdadero ($\\mu$).\n",
        "*   **Eficiencia y Consistencia:** Observaremos cómo la distribución de los estimadores se vuelve más \"apretada\" (menor varianza, más eficiente) y se concentra alrededor del valor verdadero a medida que aumentamos el tamaño de la muestra (`n`).\n",
        "\n"
      ],
      "metadata": {
        "id": "SuYBx4BBto-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar las librerías necesarias\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import interact, IntSlider, Dropdown\n",
        "\n",
        "# Estilo de gráficos\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# --- Poblaciones Pre-generadas para la Simulación ---\n",
        "# Población para estimar la Media (ej. Coeficiente Intelectual)\n",
        "media_poblacional_real = 100\n",
        "std_poblacional_real = 15\n",
        "poblacion_media = np.random.normal(media_poblacional_real, std_poblacional_real, 100000)\n",
        "\n",
        "# Población para estimar la Proporción (ej. Proporción de zurdos)\n",
        "proporcion_poblacional_real = 0.12\n",
        "poblacion_proporcion = np.random.choice([1, 0], size=100000, p=[proporcion_poblacional_real, 1 - proporcion_poblacional_real])\n",
        "\n",
        "\n",
        "def simular_propiedades_estimador(estimador='Media', tamano_muestra=30, num_muestras=2000):\n",
        "    \"\"\"\n",
        "    Función interactiva para visualizar las propiedades de los estimadores.\n",
        "    \"\"\"\n",
        "    lista_estimadores = []\n",
        "\n",
        "    if estimador == 'Media':\n",
        "        poblacion = poblacion_media\n",
        "        parametro_real = media_poblacional_real\n",
        "        for _ in range(num_muestras):\n",
        "            muestra = np.random.choice(poblacion, size=tamano_muestra)\n",
        "            estimador_calculado = np.mean(muestra)\n",
        "            lista_estimadores.append(estimador_calculado)\n",
        "    else: # Proporción\n",
        "        poblacion = poblacion_proporcion\n",
        "        parametro_real = proporcion_poblacional_real\n",
        "        for _ in range(num_muestras):\n",
        "            muestra = np.random.choice(poblacion, size=tamano_muestra)\n",
        "            estimador_calculado = np.mean(muestra) # La media de 0s y 1s es la proporción\n",
        "            lista_estimadores.append(estimador_calculado)\n",
        "\n",
        "    # --- Visualización ---\n",
        "    plt.figure(figsize=(12, 7))\n",
        "    sns.histplot(lista_estimadores, kde=True, color='royalblue', bins=50)\n",
        "\n",
        "    # Media de todos los estimadores calculados\n",
        "    media_de_estimadores = np.mean(lista_estimadores)\n",
        "    # Varianza de los estimadores (para mostrar eficiencia)\n",
        "    varianza_de_estimadores = np.var(lista_estimadores)\n",
        "\n",
        "    # Líneas verticales para comparación\n",
        "    plt.axvline(parametro_real, color='red', linestyle='--', linewidth=2.5,\n",
        "                label=f'Parámetro Poblacional Real = {parametro_real:.4f}')\n",
        "\n",
        "    plt.axvline(media_de_estimadores, color='gold', linestyle='-', linewidth=2.5,\n",
        "                label=f'Promedio de los Estimadores = {media_de_estimadores:.4f}')\n",
        "\n",
        "    plt.title(f'Distribución de {num_muestras} Estimadores Muestrales (n={tamano_muestra})', fontsize=16)\n",
        "    plt.xlabel(f\"Valor del Estimador ('{estimador}' Muestral)\")\n",
        "    plt.ylabel(\"Frecuencia\")\n",
        "    plt.legend()\n",
        "\n",
        "    # Anotación sobre eficiencia/consistencia\n",
        "    plt.annotate(f'Varianza de los estimadores: {varianza_de_estimadores:.4f}\\n(Menor varianza = Mayor eficiencia)',\n",
        "                 xy=(0.05, 0.85), xycoords='axes fraction',\n",
        "                 bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"wheat\", ec=\"black\", lw=1))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# --- Controles Interactivos ---\n",
        "interact(simular_propiedades_estimador,\n",
        "         estimador=Dropdown(options=['Media', 'Proporción'], value='Media'),\n",
        "         tamano_muestra=IntSlider(min=5, max=1000, step=5, value=30, description='Tamaño Muestra (n)'),\n",
        "         num_muestras=IntSlider(min=100, max=10000, step=100, value=2000, description='Nº de Muestras'));"
      ],
      "metadata": {
        "id": "PtVyKcBMtpK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Guía para el Estudiante (qué observar en la simulación 1):**\n",
        "\n",
        "1.  **Insesgamiento:** Fija `n=30` y `Nº de Muestras = 2000`. Observa la línea roja (el valor verdadero) y la línea dorada (el promedio de todas tus \"adivinanzas\"). **¡Están prácticamente en el mismo lugar!** Esto demuestra visualmente que la media muestral es un **estimador insesgado**: aunque cada estimación individual puede errar, en promedio, no tiene un sesgo sistemático hacia arriba o hacia abajo. Aumenta el `Nº de Muestras` a 10,000 para ver cómo la línea dorada se alinea aún más perfectamente.\n",
        "2.  **Eficiencia:** Mantén el `Nº de Muestras` fijo. Ahora, mueve el slider del `Tamaño Muestra (n)` de 10 a 500. Observa el histograma y la \"Varianza de los estimadores\". A medida que `n` aumenta, el histograma se vuelve **más alto y estrecho**. La varianza disminuye drásticamente. Esto es la **eficiencia**: un estimador basado en una muestra más grande es más eficiente porque sus valores están mucho más concentrados alrededor del parámetro real.\n",
        "3.  **Consistencia:** La consistencia es una combinación de las dos propiedades anteriores. Al aumentar `n`, no solo la distribución se vuelve más estrecha (eficiencia), sino que se estrecha *alrededor del valor verdadero* (gracias al insesgamiento). Esto significa que la probabilidad de que tu estimador esté lejos del valor real disminuye a medida que `n` crece.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "rM97PNPUuLo5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **Simulación 2: El Acto de la Estimación Puntual**\n",
        "\n",
        "Ahora, pasemos de la teoría a la práctica. ¿Qué pasa cuando, como científicos de datos, tomamos *una sola muestra*? Esta simulación se centra en ese momento.\n",
        "\n",
        "**Objetivos de la Simulación:**\n",
        "*   Visualizar la relación entre la población, una muestra aleatoria extraída de ella, y el estimador puntual resultante.\n",
        "*   Entender que cada muestra produce un estimador puntual ligeramente diferente.\n",
        "*   Ver cómo el tamaño de la muestra (`n`) hace que nuestro estimador puntual sea más o menos \"confiable\"."
      ],
      "metadata": {
        "id": "Oa-kV4X2uUx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reutilizamos las poblaciones de la simulación anterior\n",
        "\n",
        "def simular_estimacion_puntual(estimador_tipo='Media', tamano_muestra=50): # Removed boton_muestra parameter\n",
        "    \"\"\"\n",
        "    Función interactiva para visualizar una estimación puntual a partir de una única muestra.\n",
        "    \"\"\"\n",
        "    if estimador_tipo == 'Media':\n",
        "        poblacion = poblacion_media\n",
        "        parametro_real = media_poblacional_real\n",
        "        xlabel = \"Valor (ej. CI)\"\n",
        "    else: # Proporción\n",
        "        poblacion = poblacion_proporcion\n",
        "        parametro_real = proporcion_poblacional_real\n",
        "        xlabel = \"Categoría (0 o 1)\"\n",
        "\n",
        "    # 1. Tomar una única muestra de la población\n",
        "    # Ensure the sample size is not greater than the population size for replace=False\n",
        "    sample_size = min(tamano_muestra, len(poblacion))\n",
        "    muestra_actual = np.random.choice(poblacion, size=sample_size, replace=False)\n",
        "\n",
        "\n",
        "    # 2. Calcular el estimador puntual para ESTA muestra\n",
        "    estimador_puntual = np.mean(muestra_actual)\n",
        "\n",
        "    # --- Visualización ---\n",
        "    fig, ax = plt.subplots(figsize=(14, 7))\n",
        "\n",
        "    # Graficar la distribución de toda la población de fondo\n",
        "    # Adjust bins for proportion plot if necessary\n",
        "    bins = 'auto'\n",
        "    if estimador_tipo == 'Proporción':\n",
        "      bins = [-.5, .5, 1.5] # Bins to center around 0 and 1\n",
        "\n",
        "\n",
        "    sns.histplot(poblacion, kde=False, ax=ax, color='lightgray', label='Población Completa', bins=bins)\n",
        "\n",
        "\n",
        "    # Mostrar los puntos de la muestra que acabamos de tomar\n",
        "    # Usamos un rugplot para ver la distribución de los puntos muestreados\n",
        "    sns.rugplot(muestra_actual, ax=ax, height=0.1, color='darkorange', label=f'Datos en la Muestra (n={sample_size})')\n",
        "\n",
        "\n",
        "    # Líneas verticales\n",
        "    ax.axvline(parametro_real, color='red', linestyle='--', linewidth=2.5,\n",
        "                label=f'Parámetro Poblacional Real = {parametro_real:.4f}')\n",
        "\n",
        "    ax.axvline(estimador_puntual, color='green', linestyle='-', linewidth=3,\n",
        "                label=f'Estimador Puntual de esta Muestra = {estimador_puntual:.4f}')\n",
        "\n",
        "    ax.set_title(\"Estimación Puntual: Usando una Muestra para 'Adivinar' el Parámetro Poblacional\", fontsize=16)\n",
        "    ax.set_xlabel(xlabel)\n",
        "    ax.set_ylabel(\"Frecuencia\")\n",
        "    ax.legend(loc='upper right')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# --- Controles Interactivos con un botón ---\n",
        "# Usamos widgets.interactive para poder incluir un botón que no pasa su valor\n",
        "from ipywidgets import interactive, IntSlider, Button, VBox, Dropdown\n",
        "from IPython.display import display\n",
        "\n",
        "w_estimador = Dropdown(options=['Media', 'Proporción'], value='Media', description='Estimar:')\n",
        "w_tamano = IntSlider(min=10, max=500, step=10, value=50, description='Tamaño Muestra (n):')\n",
        "w_boton = Button(description=\"Tomar Nueva Muestra\")\n",
        "\n",
        "# Use interactive_output for the dropdown and slider\n",
        "out = widgets.interactive_output(simular_estimacion_puntual, {'estimador_tipo': w_estimador, 'tamano_muestra': w_tamano})\n",
        "\n",
        "# Function to call when the button is clicked\n",
        "def on_button_clicked(b):\n",
        "    simular_estimacion_puntual(estimador_tipo=w_estimador.value, tamano_muestra=w_tamano.value)\n",
        "\n",
        "# Link the button click event to the function\n",
        "w_boton.on_click(on_button_clicked)\n",
        "\n",
        "# Display the widgets and the output\n",
        "ui = VBox([w_estimador, w_tamano, w_boton])\n",
        "display(ui, out)"
      ],
      "metadata": {
        "id": "Zn2d42q0uOyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Guía para el Estudiante (qué observar en la simulación 2):**\n",
        "\n",
        "1.  **El Juego de la Inferencia:** El gráfico muestra la población entera en gris claro (algo que nunca vemos completo en la vida real). La línea roja es el valor verdadero que queremos conocer.\n",
        "2.  **Tu Única Oportunidad:** Las marcas naranjas en la base del gráfico son los datos de tu única muestra. La línea verde sólida es tu **estimación puntual** ($\\bar{X}$ o $\\hat{p}$), calculada a partir de *solo esos puntos naranjas*. Es tu \"mejor suposición\" del valor de la línea roja.\n",
        "3.  **El Rol del Azar:** **Haz clic en el botón \"Tomar Nueva Muestra\" varias veces sin cambiar `n`**. Observa cómo los puntos naranjas cambian y, en consecuencia, la línea verde (tu estimación) \"salta\" alrededor de la línea roja. A veces estará muy cerca, otras veces un poco más lejos. ¡Esa es la incertidumbre del muestreo!\n",
        "4.  **Reduciendo la Incertidumbre:** Ahora, pon el `Tamaño Muestra (n)` en un valor bajo, como 10. Presiona el botón varias veces. Verás que la línea verde salta de forma bastante salvaje. Ahora, **aumenta `n` a 500** y presiona el botón de nuevo. Los saltos de la línea verde serán mucho, mucho más pequeños. Estará consistentemente más cerca de la línea roja. Esto demuestra por qué **las muestras más grandes nos dan estimaciones puntuales más confiables**.\n",
        "\n",
        "Con estas dos simulaciones, habrán construido una intuición sólida sobre qué es un estimador, por qué usamos ciertos estimadores (como la media muestral) y cómo el tamaño de la muestra es nuestra herramienta más poderosa para mejorar la calidad de nuestras inferencias."
      ],
      "metadata": {
        "id": "f5ghjE-Gu3rh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.4. Estructura de un Intervalo de Confianza**\n",
        "\n",
        "Un **intervalo de confianza** es una gama de valores, calculada a partir de los datos de la muestra, que probablemente contenga el valor verdadero de un parámetro poblacional con un cierto nivel de confianza. Es mucho más informativo que una estimación puntual, ya que nos da una idea de la incertidumbre asociada a nuestra estimación.\n",
        "\n",
        "La estructura general de un intervalo de confianza es:\n",
        "$$\\text{Estimador Puntual} \\pm \\text{Margen de Error}$$\n",
        "\n",
        "Donde el **Margen de Error** se calcula como:\n",
        "$$\\text{Valor Crítico} \\times \\text{Error Estándar del Estimador}$$\n",
        "\n",
        "El **nivel de confianza** (por ejemplo, 95%) nos indica la probabilidad de que, si repitiéramos el proceso de muestreo y construcción de intervalos muchas veces, un cierto porcentaje de esos intervalos contendrían el verdadero parámetro poblacional. Los valores críticos más comunes para la distribución normal (que utilizamos gracias al TLC para muestras grandes) son:\n",
        "*   Para 90% de confianza: $Z_{\\alpha/2} = 1.645$\n",
        "*   Para 95% de confianza: $Z_{\\alpha/2} = 1.96$\n",
        "*   Para 99% de confianza: $Z_{\\alpha/2} = 2.576$\n",
        "\n",
        "**Para alimentar la intuición con una simulación en Python:**\n",
        "\n",
        "1.  **Visualización del Intervalo:** En un gráfico, dibuja el estimador puntual (media o proporción muestral) como un punto central. Luego, dibuja una línea o barra que se extienda a cada lado, representando el intervalo de confianza.\n",
        "2.  **Control del Nivel de Confianza:** Permite al usuario seleccionar un nivel de confianza (90%, 95%, 99%). Observen cómo el \"Margen de Error\" y, por lo tanto, el ancho del intervalo, cambia. A mayor confianza, mayor ancho del intervalo.\n",
        "\n",
        "**2.5. Intervalo de Confianza para la Media**\n",
        "\n",
        "Aquí aplicamos todo lo que hemos aprendido. Para construir un intervalo de confianza para la media poblacional ($\\mu$), usaremos la media muestral ($\\bar{X}$) y el error estándar de la media.\n",
        "\n",
        "**La fórmula para el intervalo de confianza de la media poblacional es:**\n",
        "*   Si $\\sigma$ (desviación estándar poblacional) es conocida (¡caso ideal y poco común!):\n",
        "    $$ \\bar{X} \\pm Z_{\\alpha/2} \\left( \\frac{\\sigma}{\\sqrt{n}} \\right) $$\n",
        "*   Si $\\sigma$ es desconocida (¡el caso más común en la vida real!):\n",
        "    Utilizamos la desviación estándar muestral ($s$) y en lugar de un valor $Z$, usamos un valor $t$ de la distribución t-Student, ya que introduce una corrección por la incertidumbre de estimar $\\sigma$ con $s$.\n",
        "    $$ \\bar{X} \\pm t_{n-1, \\alpha/2} \\left( \\frac{s}{\\sqrt{n}} \\right) $$\n",
        "    Aquí, $n-1$ son los grados de libertad.\n",
        "\n",
        "**Para alimentar la intuición con una simulación en Python:**\n",
        "\n",
        "1.  **Población con $\\mu$ Conocida:** Genera una población sintética con una media $\\mu$ conocida (esto es para efectos de la simulación y verificación).\n",
        "2.  **Bucle de Muestreo:** En un bucle, se toman múltiples muestras de tamaño $n$.\n",
        "3.  **Cálculo del IC:** Para cada muestra, calcula la media muestral ($\\bar{X}$) y construye su intervalo de confianza al 95% (o el nivel de confianza seleccionado por el usuario).\n",
        "4.  **Visualización del \"Captura\":** En un gráfico, dibuja cada intervalo de confianza como una línea horizontal. Dibuja una línea vertical que represente la verdadera $\\mu$ de la población. Contabiliza cuántos de los intervalos generados \"capturan\" (contienen) la línea de la $\\mu$ verdadera. Verán que aproximadamente el 95% (o el nivel de confianza elegido) de los intervalos la contienen. ¡Esto es el significado real del nivel de confianza!\n",
        "5.  **Interactividad:** Permita cambiar $n$ (tamaño de muestra) y el nivel de confianza para ver el impacto en el ancho del intervalo y la tasa de \"captura\".\n",
        "\n",
        "**2.6. Intervalo de Confianza para la Proporción**\n",
        "\n",
        "Finalmente, para estimar una proporción poblacional ($p$) y construir su intervalo de confianza, usamos la proporción muestral ($\\hat{p}$). Gracias al TLC, para muestras suficientemente grandes, la distribución muestral de $\\hat{p}$ se aproxima a una distribución normal.\n",
        "\n",
        "**La fórmula aproximada para el intervalo de confianza de la proporción poblacional es:**\n",
        "$$ \\hat{p} \\pm Z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} $$\n",
        "\n",
        "Donde $\\hat{p}(1-\\hat{p})/n$ es una estimación de la varianza del estimador de la proporción muestral.\n",
        "\n",
        "**Para alimentar la intuición con una simulación en Python (similar al de la media):**\n",
        "\n",
        "1.  **Población con $p$ Conocida:** Genera una población binaria (0s y 1s, o \"éxitos\" y \"fracasos\") con una proporción $p$ conocida.\n",
        "2.  **Bucle de Muestreo:** Toma múltiples muestras de tamaño $n$.\n",
        "3.  **Cálculo del IC:** Para cada muestra, calcula la proporción muestral ($\\hat{p}$) y construye su intervalo de confianza.\n",
        "4.  **Visualización del \"Captura\":** Dibuja cada intervalo y una línea vertical para la verdadera $p$ de la población. Contabiliza la tasa de \"captura\".\n",
        "5.  **Interactividad:** Permita cambiar $n$ y el nivel de confianza."
      ],
      "metadata": {
        "id": "TOVgOrfYuAiI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Simulación Interactiva: Capturando el Parámetro Verdadero**\n",
        "\n",
        "Esta simulación responde a la pregunta: **\"¿Qué significa realmente un 'nivel de confianza del 95%'?\"**. No significa que hay un 95% de probabilidad de que el parámetro esté en *nuestro* intervalo. Significa que si repitiéramos el experimento muchas veces, el 95% de los intervalos que construyamos contendrían el verdadero parámetro. ¡Vamos a visualizarlo!\n",
        "\n",
        "Generaremos 100 muestras distintas, construiremos un intervalo de confianza para cada una y veremos cuántos \"atrapan\" al verdadero parámetro poblacional.\n"
      ],
      "metadata": {
        "id": "cGFRFAWLtp50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar librerías adicionales\n",
        "from scipy.stats import t, norm as z_dist\n",
        "\n",
        "def simular_intervalos_confianza(parametro_a_estimar='Media', nivel_confianza=0.95, tamano_muestra=30):\n",
        "    \"\"\"\n",
        "    Función interactiva para visualizar el significado de los Intervalos de Confianza.\n",
        "    \"\"\"\n",
        "    num_simulaciones = 100\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # ----------------- SIMULACIÓN PARA LA MEDIA -----------------\n",
        "    if parametro_a_estimar == 'Media':\n",
        "        # Población con una media conocida que intentaremos \"capturar\"\n",
        "        pop_mean = 100\n",
        "        pop_std = 15\n",
        "        poblacion = np.random.normal(pop_mean, pop_std, size=50000)\n",
        "\n",
        "        parametro_verdadero = pop_mean\n",
        "        capturados = 0\n",
        "\n",
        "        for i in range(num_simulaciones):\n",
        "            # 1. Tomar una muestra\n",
        "            muestra = np.random.choice(poblacion, size=tamano_muestra)\n",
        "\n",
        "            # 2. Calcular estadísticos muestrales\n",
        "            media_muestral = np.mean(muestra)\n",
        "            std_muestral = np.std(muestra, ddof=1) # Usamos ddof=1 para la cuasivarianza\n",
        "\n",
        "            # 3. Calcular el intervalo de confianza (usando t-Student, caso realista)\n",
        "            sem = std_muestral / np.sqrt(tamano_muestra)\n",
        "            grados_libertad = tamano_muestra - 1\n",
        "            valor_critico_t = t.ppf((1 + nivel_confianza) / 2, df=grados_libertad)\n",
        "            margen_error = valor_critico_t * sem\n",
        "\n",
        "            lim_inf = media_muestral - margen_error\n",
        "            lim_sup = media_muestral + margen_error\n",
        "\n",
        "            # 4. Verificar si el intervalo \"captura\" la media verdadera\n",
        "            color = 'blue'\n",
        "            if lim_inf <= parametro_verdadero <= lim_sup:\n",
        "                capturados += 1\n",
        "            else:\n",
        "                color = 'red' # El intervalo falló\n",
        "\n",
        "            # 5. Dibujar el intervalo\n",
        "            plt.plot([lim_inf, lim_sup], [i, i], color=color, lw=1.5)\n",
        "            plt.plot(media_muestral, i, 'ko', markersize=3) # Punto para la media muestral\n",
        "\n",
        "    # ----------------- SIMULACIÓN PARA LA PROPORCIÓN -----------------\n",
        "    else: # Proporción\n",
        "        # Población con una proporción conocida\n",
        "        pop_proportion = 0.60\n",
        "        poblacion = np.random.choice([0, 1], size=50000, p=[1-pop_proportion, pop_proportion])\n",
        "\n",
        "        parametro_verdadero = pop_proportion\n",
        "        capturados = 0\n",
        "\n",
        "        for i in range(num_simulaciones):\n",
        "            muestra = np.random.choice(poblacion, size=tamano_muestra)\n",
        "            prop_muestral = np.mean(muestra)\n",
        "\n",
        "            # Evitar prop_muestral de 0 o 1 que da error en la fórmula\n",
        "            if prop_muestral == 0 or prop_muestral == 1: continue\n",
        "\n",
        "            # Usamos Z para proporciones (aproximación normal)\n",
        "            valor_critico_z = z_dist.ppf((1 + nivel_confianza) / 2)\n",
        "            margen_error = valor_critico_z * np.sqrt(prop_muestral * (1 - prop_muestral) / tamano_muestra)\n",
        "\n",
        "            lim_inf = prop_muestral - margen_error\n",
        "            lim_sup = prop_muestral + margen_error\n",
        "\n",
        "            color = 'green'\n",
        "            if lim_inf <= parametro_verdadero <= lim_sup:\n",
        "                capturados += 1\n",
        "            else:\n",
        "                color = 'red'\n",
        "\n",
        "            plt.plot([lim_inf, lim_sup], [i, i], color=color, lw=1.5)\n",
        "            plt.plot(prop_muestral, i, 'ko', markersize=3)\n",
        "\n",
        "    # --- Configuración final del gráfico ---\n",
        "    plt.axvline(parametro_verdadero, color='black', linestyle='--', lw=2, label=f'Parámetro Verdadero = {parametro_verdadero:.2f}')\n",
        "\n",
        "    tasa_captura = (capturados / num_simulaciones) * 100\n",
        "    plt.title(f'Simulación de {num_simulaciones} Intervalos de Confianza\\n'\n",
        "              f'Nivel de Confianza: {nivel_confianza*100}%, Tamaño de Muestra (n): {tamano_muestra}\\n'\n",
        "              f'Tasa de Captura Real: {tasa_captura:.0f}%', fontsize=15)\n",
        "\n",
        "    plt.xlabel(f\"Valor del Intervalo de Confianza para la {parametro_a_estimar}\")\n",
        "    plt.ylabel(\"Número de Simulación\")\n",
        "    plt.yticks([]) # Ocultar los ticks del eje y para mayor claridad\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.show()\n",
        "\n",
        "# --- Crear los controles interactivos ---\n",
        "interact(simular_intervalos_confianza,\n",
        "         parametro_a_estimar=Dropdown(options=['Media', 'Proporción'], value='Media'),\n",
        "         nivel_confianza=widgets.FloatSlider(min=0.50, max=0.99, step=0.01, value=0.95, description='Nivel Confianza'),\n",
        "         tamano_muestra=IntSlider(min=10, max=1000, step=10, value=30, description='Tamaño Muestra (n)'));"
      ],
      "metadata": {
        "id": "Grps9OSCtpdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Guía para el Estudiante (qué observar en la simulación):**\n",
        "\n",
        "1.  **El Significado de la Confianza:** Elige `Media`, `Nivel Confianza = 0.95` y `n=30`. Ejecuta la simulación. Verás una línea negra vertical (la media real de la población, que en la vida real desconoceríamos). Verás 100 líneas horizontales, cada una es un IC de una muestra diferente. La mayoría son azules (o verdes), indicando que \"capturan\" la línea negra. Algunas son rojas, indicando que fallaron. **El título te dirá la \"Tasa de Captura Real\". ¡Debería estar muy cerca del 95%!** Esto demuestra que el nivel de confianza es una tasa de éxito a largo plazo.\n",
        "2.  **Confianza vs. Precisión (Ancho del Intervalo):** Mantén `n` fijo. Ahora, **aumenta el `Nivel Confianza` a 0.99**. Observa dos cosas: a) los intervalos se vuelven notablemente más anchos, y b) la tasa de captura se acerca al 99% (menos intervalos rojos). Ahora, bájalo a 0.80. Los intervalos se encogen (son más \"precisos\"), pero la tasa de captura baja al 80% (más fallos). Esta es la compensación fundamental: **para estar más seguro (mayor confianza), debes aceptar un rango de valores más amplio (menor precisión)**.\n",
        "3.  **El Poder del Tamaño de Muestra:** Fija el `Nivel Confianza` en 0.95. Ahora, **aumenta el `Tamaño Muestra (n)` a 200**. Observa cómo todos los intervalos se vuelven mucho más cortos. Esto es porque el SEM disminuye con $\\sqrt{n}$. Con una muestra más grande, nuestra estimación es más precisa, y podemos construir un intervalo más estrecho manteniendo el mismo nivel de confianza.\n",
        "4.  **Intervalos para Proporción:** Cambia el `parámetro_a_estimar` a `Proporción`. La lógica es exactamente la misma, solo cambian las fórmulas internas. Esto refuerza la idea de que la **estructura conceptual de un intervalo de confianza (`estimador ± margen de error`)** es universal.\n"
      ],
      "metadata": {
        "id": "V4Nxkechn5Gd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AYnL6b5DvfmD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}